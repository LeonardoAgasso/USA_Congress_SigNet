{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic disaggregation\n",
    "\n",
    "### Repeat the same process on data previously disaggregated according to the categories of the vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import glob, os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../local/bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge categories into \"clustered topics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_congress_files(folder_names, merged_folder_name):\n",
    "    # Create the merged folder if it doesn't exist\n",
    "    if not os.path.exists(merged_folder_name):\n",
    "        os.makedirs(merged_folder_name)\n",
    "\n",
    "    for category in folder_names:\n",
    "        category_folder = os.path.join(os.getcwd(), category)\n",
    "        merged_folder = os.path.join(os.getcwd(), merged_folder_name)\n",
    "\n",
    "        # Iterate through the files in the category folder\n",
    "        for root, _, files in os.walk(category_folder):\n",
    "            for file in files:\n",
    "                if file.startswith(\"congress_\") and file.endswith(\".csv\"):\n",
    "                    congress_number = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "                    congress_file = os.path.join(root, file)\n",
    "                    merged_congress_file = os.path.join(merged_folder, f\"congress_{congress_number}.csv\")\n",
    "\n",
    "                    # If the file already exists in the merged folder, append data\n",
    "                    if os.path.exists(merged_congress_file):\n",
    "                        existing_data = pd.read_csv(merged_congress_file)\n",
    "                        new_data = pd.read_csv(congress_file)\n",
    "                        merged_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "                        merged_data.to_csv(merged_congress_file, index=False)\n",
    "                    else:\n",
    "                        # If the file doesn't exist in the merged folder, copy it\n",
    "                        shutil.copy(congress_file, merged_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_members_df(members, party_codes):\n",
    "    temp_congress = members.groupby('icpsr', as_index=False)[['congress']].agg(lambda x: list(x))                                                           # group by icpsr and aggregate the congress numbers into a list\n",
    "    temp_party = members.groupby('icpsr', as_index=False)[['party_code']].agg(lambda x: list(set(x)))                                                       # group by icpsr and aggregate the party codes into a list\n",
    "    temp_congress = temp_congress.merge(temp_party)                                                                                                         # merge the two dataframes\n",
    "    temp_congress['bioname'] = temp_congress['icpsr'].map(members[['icpsr', 'bioname']].set_index('icpsr').to_dict()['bioname'])                            # insert the bioname based on the icpsr \n",
    "    temp_congress['state_abbrev'] = temp_congress['icpsr'].map(members[['icpsr', 'state_abbrev']].set_index('icpsr').to_dict()['state_abbrev'])             # insert the state_abbrev based on the icpsr\n",
    "    party_codes_dic = party_codes[['party_name', 'party_code']].set_index('party_code').to_dict()['party_name']                                             # create a dictionary for the party codes\n",
    "    temp_congress['party_name'] = temp_congress['party_code'].apply(lambda x: [party_codes_dic[y] for y in x])                                              # insert the party name based on the party code\n",
    "    return temp_congress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate meaningful sets listing the categories belonging to each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamber = 'senate'\n",
    "category_set = 'peltzman'\n",
    "p = '../dataset/votes_'+chamber+'_'+category_set+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal = [p+'Budget_General_Interest/', \n",
    "\t\t\tp+'Budget_Special_Interest/',\n",
    "\t\t\tp+'Regulation_General_Interest/', \n",
    "\t\t\tp+'Regulation_Special_Interest/', \n",
    "\t\t\tp+'Domestic_Social_Policy/', \n",
    "\t\t\tp+'Government_Organization/',\n",
    "\t\t\tp+'Internal_Organization/',\n",
    "\t\t\tp+'D._C./']\n",
    "\n",
    "foreign = [\tp+'Defense_Policy_Budget/',\n",
    "\t\t\tp+'Defense_Policy_Resolution/',\n",
    "\t\t\tp+'Foreign_Policy_Budget/',\n",
    "\t\t\tp+'Foreign_Policy_Resolution/',\n",
    "\t\t   \tp+'Indian_Affairs/']\n",
    "\n",
    "internal_folder = p+'internal/'\n",
    "foreign_folder = p+'foreign/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_peltz = ['Budget General Interest','Budget Special Interest','Regulation General Interest','Regulation Special Interest','Domestic Social Policy','Government Organization','Internal Organization','D. C.']\n",
    "foreign_peltz = ['Defense Policy Budget','Defense Policy Resolution','Foreign Policy Budget','Foreign Policy Resolution','Indian Affairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(internal_peltz), len(foreign_peltz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(internal_folder):\n",
    "\tos.makedirs(internal_folder)\n",
    "\n",
    "if not os.path.exists(foreign_folder):\n",
    "\tos.makedirs(foreign_folder)\n",
    "\n",
    "merge_congress_files(internal, internal_folder)\n",
    "merge_congress_files(foreign, foreign_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_internal = '../dataset/edgelists/votes_'+chamber+'_peltzman_edges/internal/'\n",
    "output_folder_foreign = '../dataset/edgelists/votes_'+chamber+'_peltzman_edges/foreign/'\n",
    "\n",
    "if not os.path.exists(output_folder_internal):\n",
    "    os.makedirs(output_folder_internal)\n",
    "\n",
    "if not os.path.exists(output_folder_foreign):\n",
    "    os.makedirs(output_folder_foreign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv('../dataset/HSall_members.csv')\n",
    "party_codes = pd.read_csv('../dataset/HSall_parties.csv')\n",
    "\n",
    "members_info = create_members_df(members, party_codes)\n",
    "\n",
    "member_party_dict = members_info.set_index('icpsr')['party_name'].to_dict()\t\t# member_id -> party_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edgelist_from_congress(congress, members_party_dict):\n",
    "\tedgelist = pd.DataFrame()\n",
    "\n",
    "\tfor voteid in tqdm(set(congress['id'])):                 # iterate over all votes id (ids are unique for each vote)\n",
    "\n",
    "\t\ttemp = congress[congress['id'] == voteid]            # select the rows where the vote id is equal to the current vote id            \n",
    "\n",
    "\t\tyy = temp[temp['vote']=='Yea']['icpsr']              # select the icpsr of the members that voted \"Yea\"\n",
    "\t\tnn = temp[temp['vote']=='Nay']['icpsr']                         \n",
    "\n",
    "\t\ty = itertools.combinations(yy, 2)                    # all possible combinations of 2 members that voted \"Yea\"\n",
    "\t\tn = itertools.combinations(nn, 2)                \n",
    "\t\to = itertools.product(yy, nn)                        # cartesian product of the 2 series\n",
    "\n",
    "\t\ty = pd.DataFrame(y, columns = ['source', 'target'])  # create a dataframe from the combinations of \"Yea\" voters\n",
    "\t\ty['weight'] = 1                                      # add a column with the weight of the edge\n",
    "\t\ty['count'] = 1                                         \n",
    "\n",
    "\t\tn = pd.DataFrame(n, columns = ['source', 'target'])     \n",
    "\t\tn['weight'] = 1                                         \n",
    "\t\tn['count'] = 1                                          \n",
    "\n",
    "\t\to = pd.DataFrame(o, columns = ['source', 'target'])     \n",
    "\t\to['weight'] = -1                                     # same but the link is negative                    \n",
    "\t\to['count'] = 1                                          \n",
    "\n",
    "\t\tedgelist = pd.concat([edgelist, y, n, o])\n",
    "\t\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count                  \n",
    "\n",
    "\tedgelist = pd.concat([edgelist, pd.DataFrame({\n",
    "\t\t'source': edgelist['target'],                        # new columns based on old columns: \n",
    "\t\t'target': edgelist['source'],                        #   'newcolumn': dataframe['oldcolumn']\n",
    "\t\t'weight': edgelist['weight'],\n",
    "\t\t'count': edgelist['count']})])\n",
    "\n",
    "\tedgelist = edgelist.loc[edgelist['source'] < edgelist['target']]                    # remove duplicates\n",
    "\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count\n",
    "\tedgelist['party'] = edgelist.apply(lambda row: 'in' if members_party_dict[row['source']] == members_party_dict[row['target']] else 'out', axis=1)   # create a column with the party of the edge\n",
    "\n",
    "\tmap_votes = edgelist.groupby(['source', 'target'])['count'].sum().to_dict()                                                                         # create a dictionary with the number of votes togheter for each pair of nodes                               \n",
    "\n",
    "\tedgelist['votes_togheter'] = edgelist[['source', 'target']].apply(lambda x: map_votes[(x['source'], x['target'])], axis=1)\n",
    "\tedgelist['perc'] = edgelist['count']/edgelist['votes_togheter']\n",
    "\n",
    "\treturn edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 573/573 [00:11<00:00, 50.85it/s]\n",
      "100%|██████████| 470/470 [00:08<00:00, 58.59it/s]\n",
      "100%|██████████| 547/547 [00:08<00:00, 61.88it/s]\n",
      "100%|██████████| 887/887 [00:16<00:00, 54.98it/s]\n",
      "100%|██████████| 135/135 [00:01<00:00, 79.25it/s]\n",
      "100%|██████████| 449/449 [00:06<00:00, 66.07it/s]\n",
      "100%|██████████| 792/792 [00:14<00:00, 55.15it/s]\n",
      "100%|██████████| 365/365 [00:05<00:00, 66.56it/s]\n",
      "100%|██████████| 1134/1134 [00:22<00:00, 51.37it/s]\n",
      "100%|██████████| 327/327 [00:04<00:00, 72.15it/s]\n",
      "100%|██████████| 574/574 [00:10<00:00, 56.42it/s]\n",
      "100%|██████████| 464/464 [00:07<00:00, 61.50it/s]\n",
      "100%|██████████| 202/202 [00:02<00:00, 74.56it/s]\n",
      "100%|██████████| 506/506 [00:07<00:00, 63.84it/s]\n",
      "100%|██████████| 472/472 [00:07<00:00, 59.63it/s]\n",
      "100%|██████████| 493/493 [00:08<00:00, 61.35it/s]\n",
      "100%|██████████| 673/673 [00:12<00:00, 55.26it/s]\n",
      "100%|██████████| 423/423 [00:06<00:00, 64.69it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 70.07it/s]\n",
      "100%|██████████| 178/178 [00:02<00:00, 83.67it/s]\n",
      "100%|██████████| 796/796 [00:14<00:00, 54.20it/s]\n",
      "100%|██████████| 326/326 [00:05<00:00, 64.17it/s]\n",
      "100%|██████████| 612/612 [00:11<00:00, 55.36it/s]\n",
      "100%|██████████| 952/952 [00:17<00:00, 53.54it/s]\n",
      "100%|██████████| 145/145 [00:01<00:00, 88.20it/s]\n",
      "100%|██████████| 596/596 [00:09<00:00, 60.43it/s]\n",
      "100%|██████████| 514/514 [00:08<00:00, 64.23it/s]\n",
      "100%|██████████| 499/499 [00:08<00:00, 59.40it/s]\n",
      "100%|██████████| 893/893 [00:16<00:00, 53.49it/s]\n",
      "100%|██████████| 406/406 [00:06<00:00, 64.60it/s]\n",
      "100%|██████████| 602/602 [00:09<00:00, 63.91it/s]\n",
      "100%|██████████| 103/103 [00:01<00:00, 84.58it/s]\n",
      "100%|██████████| 427/427 [00:06<00:00, 68.96it/s]\n",
      "100%|██████████| 187/187 [00:01<00:00, 99.50it/s] \n",
      "100%|██████████| 231/231 [00:02<00:00, 91.95it/s]\n",
      "100%|██████████| 597/597 [00:08<00:00, 69.01it/s]\n",
      "100%|██████████| 162/162 [00:01<00:00, 83.43it/s]\n",
      "100%|██████████| 37/37 [05:14<00:00,  8.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/votes_'+chamber+'_peltzman/internal/*')):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_'+chamber+'_peltzman_edges/internal/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 78.55it/s]\n",
      "100%|██████████| 122/122 [00:01<00:00, 61.13it/s]\n",
      "100%|██████████| 68/68 [00:01<00:00, 61.69it/s]\n",
      "100%|██████████| 68/68 [00:01<00:00, 63.47it/s]\n",
      "100%|██████████| 81/81 [00:01<00:00, 60.21it/s]\n",
      "100%|██████████| 116/116 [00:01<00:00, 61.45it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 66.64it/s]\n",
      "100%|██████████| 121/121 [00:01<00:00, 60.78it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 71.87it/s]\n",
      "100%|██████████| 117/117 [00:01<00:00, 66.16it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 62.32it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.81it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 75.43it/s]\n",
      "100%|██████████| 140/140 [00:02<00:00, 62.03it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 68.17it/s]\n",
      "100%|██████████| 96/96 [00:01<00:00, 67.09it/s]\n",
      "100%|██████████| 235/235 [00:03<00:00, 68.47it/s]\n",
      "100%|██████████| 71/71 [00:00<00:00, 74.27it/s]\n",
      "100%|██████████| 105/105 [00:01<00:00, 68.10it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 77.49it/s]\n",
      "100%|██████████| 88/88 [00:01<00:00, 64.55it/s]\n",
      "100%|██████████| 93/93 [00:01<00:00, 66.68it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 69.32it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 74.69it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 74.81it/s]\n",
      "100%|██████████| 72/72 [00:01<00:00, 69.94it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 72.79it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 61.67it/s]\n",
      "100%|██████████| 199/199 [00:02<00:00, 66.44it/s]\n",
      "100%|██████████| 111/111 [00:01<00:00, 63.46it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 41.00it/s]\n",
      "100%|██████████| 71/71 [00:01<00:00, 68.21it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 67.52it/s]\n",
      "100%|██████████| 57/57 [00:00<00:00, 66.52it/s]\n",
      "100%|██████████| 71/71 [00:01<00:00, 61.68it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 73.54it/s]\n",
      "100%|██████████| 149/149 [00:01<00:00, 76.61it/s]\n",
      "100%|██████████| 37/37 [00:59<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/votes_'+chamber+'_peltzman/foreign/*')):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_'+chamber+'_peltzman_edges/foreign/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and create thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold_intersx(df, weight):\t#df is the edgelist, weight is the weight of the edge\n",
    "\n",
    "\tdef _midpoint(p1, p2):\n",
    "\t\treturn {'x': (p1['x']+p2['x'])/2, 'y': (p1['y']+p2['y'])/2}\n",
    "\n",
    "\tdef line_intersection(in_party, out_party, intersect_points):\n",
    "\t\tindex_in = np.argmax(in_party[1])\n",
    "\t\tindex_out = np.argmax(out_party[1])\n",
    "\n",
    "        # points of the mean of the distributions \n",
    "\t\tpoint_in={'x': in_party[0][index_in], 'y': in_party[1][index_in]}\n",
    "\t\tpoint_out={'x': out_party[0][index_out], 'y': out_party[1][index_out]}\n",
    "\n",
    "        # medianpoint (mean of the means) of the two distributions\n",
    "\t\tmidpoint = _midpoint(point_in, point_out)\n",
    "        \n",
    "        #find index of intersection closer to midpoint\n",
    "\t\tindex_closer = np.argmin([np.sqrt( (p[0] - midpoint['x'])**2 + (p[1] - midpoint['y'])**2 ) for p in intersect_points])\n",
    "\n",
    "        # return x value of closer intersection\n",
    "\t\treturn intersect_points[index_closer][0]\n",
    "\n",
    "\tx0 = df.loc[(df['party']=='in')&(df['weight'] == weight)]['perc']\n",
    "\tx1 = df.loc[(df['party']=='out')&(df['weight'] == weight)]['perc']\n",
    "    \n",
    "\tbw = len(x0)**(-1./(2+4))\n",
    "\tkde0 = gaussian_kde(x0, bw_method=bw)\n",
    "\tbw = len(x1)**(-1./(2+4))\n",
    "\tkde1 = gaussian_kde(x1, bw_method=bw)\n",
    "\n",
    "\txmin = min(x0.min(), x1.min())\n",
    "\txmax = max(x0.max(), x1.max())\n",
    "\tdx = 0.2 * (xmax - xmin) # add a 20% margin, as the kde is wider than the data\n",
    "\txmin -= dx\n",
    "\txmax += dx\n",
    "\n",
    "\tx = np.linspace(xmin, xmax, 500)\n",
    "\tkde0_x = kde0(x)\n",
    "\tkde1_x = kde1(x)\n",
    "\tinters_x = np.minimum(kde0_x, kde1_x)\n",
    "\n",
    "\tidx = np.argwhere(np.diff(np.sign(kde0_x - kde1_x))).flatten()\n",
    "    \n",
    "\tthreshold = line_intersection([x, kde0_x], [x, kde0_x], [[x,y] for x,y in zip (x[idx], kde1_x[idx])])\n",
    "\tarea_inters_x = np.trapz(inters_x, x)\n",
    "\n",
    "\treturn threshold, area_inters_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_thresholds_folder_internal = '../dataset/thresholds/'+chamber+'_peltzman_thresholds/internal/'\n",
    "output_thresholds_folder_foreign = '../dataset/thresholds/'+chamber+'_peltzman_thresholds/foreign/'\n",
    "\n",
    "if not os.path.exists(output_thresholds_folder_internal):\n",
    "    os.makedirs(output_thresholds_folder_internal)\n",
    "\n",
    "if not os.path.exists(output_thresholds_folder_foreign):\n",
    "    os.makedirs(output_thresholds_folder_foreign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Peltzman categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:10<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/edgelists/votes_'+chamber+'_peltzman_edges/internal/*')):\n",
    "\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\tdf_edges = pd.read_csv(csv)\n",
    "\tlen_df = 0\n",
    "\n",
    "\t#as \"n_votes\" count the number of different occurences in the column \"bill_number\" in the correspoding votes file\n",
    "\tlen_df = len(pd.read_csv('../dataset/votes_'+chamber+'_peltzman/internal/congress_' + str(n_congress) + '.csv')['bill_number'].unique())\n",
    "\t\n",
    "\tthreshold_pos, area_pos = compute_threshold_intersx(df_edges, 1)\n",
    "\tthreshold_neg, area_neg = compute_threshold_intersx(df_edges, -1)\n",
    "\n",
    "\t# Create a DataFrame with the desired columns and header\n",
    "\tdf_output = pd.DataFrame({\n",
    "\t\t'pos_threshold': [threshold_pos],\n",
    "\t\t'pos_area': [area_pos],\n",
    "\t\t'neg_threshold': [threshold_neg],\n",
    "\t\t'neg_area': [area_neg],\n",
    "\t\t'n_votes': [len_df]\n",
    "\t})\n",
    "\n",
    "\t# Save the DataFrame to CSV with the specified filename and header\n",
    "\toutput_filename = f'{n_congress}_dic_thresholds_norm.csv'\n",
    "\tdf_output.to_csv('../dataset/thresholds/'+chamber+'_peltzman_thresholds/internal/' + output_filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foreign peltzman categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:05<00:00,  7.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/edgelists/votes_'+chamber+'_peltzman_edges/foreign/*')):\n",
    "\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\tdf_edges = pd.read_csv(csv)\n",
    "\tlen_df = 0\n",
    "\n",
    "\t#as \"n_votes\" count the number of different occurences in the column \"bill_number\" in the correspoding votes file\n",
    "\tlen_df = len(pd.read_csv('../dataset/votes_'+chamber+'_peltzman/foreign/congress_' + str(n_congress) + '.csv')['bill_number'].unique())\n",
    "\n",
    "\tthreshold_pos, area_pos = compute_threshold_intersx(df_edges, 1)\n",
    "\tthreshold_neg, area_neg = compute_threshold_intersx(df_edges, -1)\n",
    "\n",
    "\t# Create a DataFrame with the desired columns and header\n",
    "\tdf_output = pd.DataFrame({\n",
    "\t\t'pos_threshold': [threshold_pos],\n",
    "\t\t'pos_area': [area_pos],\n",
    "\t\t'neg_threshold': [threshold_neg],\n",
    "\t\t'neg_area': [area_neg],\n",
    "\t\t'n_votes': [len_df]\n",
    "\t})\n",
    "\n",
    "\t# Save the DataFrame to CSV with the specified filename and header\n",
    "\toutput_filename = f'{n_congress}_dic_thresholds_norm.csv'\n",
    "\tdf_output.to_csv('../dataset/thresholds/'+chamber+'_peltzman_thresholds/foreign/' + output_filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USA_Congress_SigNetEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
