{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic disaggregation\n",
    "\n",
    "### Repeat the same process on data previously disaggregated according to the categories of the vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import glob, os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../local/bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge categories into \"clustered topics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_congress_files(folder_names, merged_folder_name):\n",
    "    # Create the merged folder if it doesn't exist\n",
    "    if not os.path.exists(merged_folder_name):\n",
    "        os.makedirs(merged_folder_name)\n",
    "\n",
    "    for category in folder_names:\n",
    "        category_folder = os.path.join(os.getcwd(), category)\n",
    "        merged_folder = os.path.join(os.getcwd(), merged_folder_name)\n",
    "\n",
    "        # Iterate through the files in the category folder\n",
    "        for root, _, files in os.walk(category_folder):\n",
    "            for file in files:\n",
    "                if file.startswith(\"congress_\") and file.endswith(\".csv\"):\n",
    "                    congress_number = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "                    congress_file = os.path.join(root, file)\n",
    "                    merged_congress_file = os.path.join(merged_folder, f\"congress_{congress_number}.csv\")\n",
    "\n",
    "                    # If the file already exists in the merged folder, append data\n",
    "                    if os.path.exists(merged_congress_file):\n",
    "                        existing_data = pd.read_csv(merged_congress_file)\n",
    "                        new_data = pd.read_csv(congress_file)\n",
    "                        merged_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "                        merged_data.to_csv(merged_congress_file, index=False)\n",
    "                    else:\n",
    "                        # If the file doesn't exist in the merged folder, copy it\n",
    "                        shutil.copy(congress_file, merged_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "category_folders = [\"../dataset/votes_house_clausen/Civil_Liberties/\", \"../dataset/votes_house_clausen/Miscellaneous_Policy/\", \"../dataset/votes_house_clausen/Government_Management/\"]\n",
    "merged_folder = \"../dataset/try_merged/\"\n",
    "merge_congress_files(category_folders, merged_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate meaningful sets listing the categories belonging to each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamber = 'house'\n",
    "category_set = 'peltzman'\n",
    "p = '../dataset/votes_'+chamber+'_'+category_set+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal = [p+'Budget_General_Interest/', \n",
    "\t\t\tp+'Budget_Special_Interest/',\n",
    "\t\t\tp+'Regulation_General_Interest/', \n",
    "\t\t\tp+'Regulation_Special_Interest/', \n",
    "\t\t\tp+'Domestic_Social_Policy/', \n",
    "\t\t\tp+'Government_Organization/',\n",
    "\t\t\tp+'Internal_Organization/',\n",
    "\t\t\tp+'D._C./']\n",
    "foreign = [\tp+'Defense_Policy_Budget/',\n",
    "\t\t\tp+'Defense_Policy_Resolution/',\n",
    "\t\t\tp+'Foreign_Policy_Budget/',\n",
    "\t\t\tp+'Foreign_Policy_Resolution/',\n",
    "\t\t   \tp+'Indian_Affairs/']\n",
    "\n",
    "internal_folder = p+'internal/'\n",
    "foreign_folder = p+'foreign/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1028/1987237459.py:21: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_data = pd.read_csv(congress_file)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(internal_folder):\n",
    "\tos.makedirs(internal_folder)\n",
    "\n",
    "if not os.path.exists(foreign_folder):\n",
    "\tos.makedirs(foreign_folder)\n",
    "\n",
    "merge_congress_files(internal, internal_folder)\n",
    "merge_congress_files(foreign, foreign_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv('../dataset/HSall_members.csv')\n",
    "party_codes = pd.read_csv('../dataset/HSall_parties.csv')\n",
    "\n",
    "members_info = create_members_df(members, party_codes)\n",
    "\n",
    "member_party_dict = members_info.set_index('icpsr')['party_name'].to_dict()\t\t# member_id -> party_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_members_df(members, party_codes):\n",
    "    temp_congress = members.groupby('icpsr', as_index=False)[['congress']].agg(lambda x: list(x))                                                           # group by icpsr and aggregate the congress numbers into a list\n",
    "    temp_party = members.groupby('icpsr', as_index=False)[['party_code']].agg(lambda x: list(set(x)))                                                       # group by icpsr and aggregate the party codes into a list\n",
    "    temp_congress = temp_congress.merge(temp_party)                                                                                                         # merge the two dataframes\n",
    "    temp_congress['bioname'] = temp_congress['icpsr'].map(members[['icpsr', 'bioname']].set_index('icpsr').to_dict()['bioname'])                            # insert the bioname based on the icpsr \n",
    "    temp_congress['state_abbrev'] = temp_congress['icpsr'].map(members[['icpsr', 'state_abbrev']].set_index('icpsr').to_dict()['state_abbrev'])             # insert the state_abbrev based on the icpsr\n",
    "    party_codes_dic = party_codes[['party_name', 'party_code']].set_index('party_code').to_dict()['party_name']                                             # create a dictionary for the party codes\n",
    "    temp_congress['party_name'] = temp_congress['party_code'].apply(lambda x: [party_codes_dic[y] for y in x])                                              # insert the party name based on the party code\n",
    "    return temp_congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edgelist_from_congress(congress, members_party_dict):\n",
    "\tedgelist = pd.DataFrame()\n",
    "\n",
    "\tfor voteid in tqdm(set(congress['id'])):                 # iterate over all votes id (ids are unique for each vote)\n",
    "\n",
    "\t\ttemp = congress[congress['id'] == voteid]            # select the rows where the vote id is equal to the current vote id            \n",
    "\n",
    "\t\tyy = temp[temp['vote']=='Yea']['icpsr']              # select the icpsr of the members that voted \"Yea\"\n",
    "\t\tnn = temp[temp['vote']=='Nay']['icpsr']                         \n",
    "\n",
    "\t\ty = itertools.combinations(yy, 2)                    # all possible combinations of 2 members that voted \"Yea\"\n",
    "\t\tn = itertools.combinations(nn, 2)                \n",
    "\t\to = itertools.product(yy, nn)                        # cartesian product of the 2 series\n",
    "\n",
    "\t\ty = pd.DataFrame(y, columns = ['source', 'target'])  # create a dataframe from the combinations of \"Yea\" voters\n",
    "\t\ty['weight'] = 1                                      # add a column with the weight of the edge\n",
    "\t\ty['count'] = 1                                         \n",
    "\n",
    "\t\tn = pd.DataFrame(n, columns = ['source', 'target'])     \n",
    "\t\tn['weight'] = 1                                         \n",
    "\t\tn['count'] = 1                                          \n",
    "\n",
    "\t\to = pd.DataFrame(o, columns = ['source', 'target'])     \n",
    "\t\to['weight'] = -1                                     # same but the link is negative                    \n",
    "\t\to['count'] = 1                                          \n",
    "\n",
    "\t\tedgelist = pd.concat([edgelist, y, n, o])\n",
    "\t\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count                  \n",
    "\n",
    "\tedgelist = pd.concat([edgelist, pd.DataFrame({\n",
    "\t\t'source': edgelist['target'],                        # new columns based on old columns: \n",
    "\t\t'target': edgelist['source'],                        #   'newcolumn': dataframe['oldcolumn']\n",
    "\t\t'weight': edgelist['weight'],\n",
    "\t\t'count': edgelist['count']})])\n",
    "\n",
    "\tedgelist = edgelist.loc[edgelist['source'] < edgelist['target']]                    # remove duplicates\n",
    "\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count\n",
    "\tedgelist['party'] = edgelist.apply(lambda row: 'in' if members_party_dict[row['source']] == members_party_dict[row['target']] else 'out', axis=1)   # create a column with the party of the edge\n",
    "\n",
    "\tmap_votes = edgelist.groupby(['source', 'target'])['count'].sum().to_dict()                                                                         # create a dictionary with the number of votes togheter for each pair of nodes                               \n",
    "\n",
    "\tedgelist['votes_togheter'] = edgelist[['source', 'target']].apply(lambda x: map_votes[(x['source'], x['target'])], axis=1)\n",
    "\tedgelist['perc'] = edgelist['count']/edgelist['votes_togheter']\n",
    "\n",
    "\treturn edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:09<00:00, 15.70it/s]\n",
      "100%|██████████| 136/136 [00:08<00:00, 16.08it/s]\n",
      "100%|██████████| 406/406 [00:27<00:00, 14.77it/s]\n",
      "100%|██████████| 722/722 [00:56<00:00, 12.76it/s]\n",
      "100%|██████████| 677/677 [00:54<00:00, 12.45it/s]\n",
      "100%|██████████| 659/659 [00:51<00:00, 12.89it/s]\n",
      "100%|██████████| 118/118 [00:08<00:00, 14.29it/s]\n",
      "100%|██████████| 533/533 [00:38<00:00, 13.73it/s]\n",
      "100%|██████████| 802/802 [01:11<00:00, 11.17it/s]\n",
      "100%|██████████| 943/943 [01:16<00:00, 12.28it/s]\n",
      "100%|██████████| 108/108 [00:06<00:00, 17.53it/s]\n",
      "100%|██████████| 187/187 [00:11<00:00, 15.72it/s]\n",
      "100%|██████████| 1430/1430 [02:20<00:00, 10.19it/s]\n",
      "100%|██████████| 680/680 [00:55<00:00, 12.22it/s]\n",
      "100%|██████████| 1227/1227 [01:46<00:00, 11.48it/s]\n",
      "100%|██████████| 116/116 [00:07<00:00, 14.94it/s]\n",
      "100%|██████████| 155/155 [00:10<00:00, 14.90it/s]\n",
      "100%|██████████| 722/722 [00:57<00:00, 12.65it/s]\n",
      "100%|██████████| 916/916 [01:19<00:00, 11.46it/s]\n",
      "100%|██████████| 988/988 [01:33<00:00, 10.52it/s]\n",
      "100%|██████████| 371/371 [00:26<00:00, 14.22it/s]\n",
      "100%|██████████| 896/896 [01:12<00:00, 12.28it/s]\n",
      "100%|██████████| 1284/1284 [01:55<00:00, 11.13it/s]\n",
      "100%|██████████| 822/822 [01:12<00:00, 11.26it/s]\n",
      "100%|██████████| 1066/1066 [01:29<00:00, 11.92it/s]\n",
      "100%|██████████| 976/976 [01:20<00:00, 12.16it/s]\n",
      "100%|██████████| 320/320 [00:23<00:00, 13.70it/s]\n",
      "100%|██████████| 1335/1335 [02:14<00:00,  9.89it/s]\n",
      "100%|██████████| 188/188 [00:11<00:00, 16.07it/s]\n",
      "100%|██████████| 896/896 [01:20<00:00, 11.06it/s]\n",
      "100%|██████████| 189/189 [00:11<00:00, 16.83it/s]\n",
      "100%|██████████| 971/971 [01:24<00:00, 11.47it/s]\n",
      "100%|██████████| 135/135 [00:08<00:00, 15.32it/s]\n",
      "100%|██████████| 91/91 [00:05<00:00, 17.97it/s]\n",
      "100%|██████████| 1103/1103 [01:37<00:00, 11.33it/s]\n",
      "100%|██████████| 633/633 [00:48<00:00, 13.17it/s]\n",
      "100%|██████████| 216/216 [00:14<00:00, 15.34it/s]\n",
      "100%|██████████| 37/37 [34:10<00:00, 55.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/votes_house_peltzman/Internal/*')):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_house_peltzman_edges/Internal/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.56it/s]\n",
      "100%|██████████| 27/27 [00:01<00:00, 17.01it/s]\n",
      "100%|██████████| 55/55 [00:03<00:00, 15.59it/s]\n",
      "100%|██████████| 121/121 [00:08<00:00, 13.82it/s]\n",
      "100%|██████████| 122/122 [00:08<00:00, 14.26it/s]\n",
      "100%|██████████| 157/157 [00:11<00:00, 13.73it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 13.82it/s]\n",
      "100%|██████████| 95/95 [00:06<00:00, 15.66it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 13.34it/s]\n",
      "100%|██████████| 129/129 [00:09<00:00, 13.64it/s]\n",
      "100%|██████████| 36/36 [00:02<00:00, 14.67it/s]\n",
      "100%|██████████| 33/33 [00:02<00:00, 14.11it/s]\n",
      "100%|██████████| 271/271 [00:22<00:00, 12.26it/s]\n",
      "100%|██████████| 234/234 [00:17<00:00, 13.51it/s]\n",
      "100%|██████████| 239/239 [00:16<00:00, 14.10it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.83it/s]\n",
      "100%|██████████| 26/26 [00:01<00:00, 15.07it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.92it/s]\n",
      "100%|██████████| 148/148 [00:11<00:00, 13.27it/s]\n",
      "100%|██████████| 120/120 [00:08<00:00, 13.52it/s]\n",
      "100%|██████████| 57/57 [00:03<00:00, 16.18it/s]\n",
      "100%|██████████| 158/158 [00:10<00:00, 14.53it/s]\n",
      "100%|██████████| 264/264 [00:19<00:00, 13.53it/s]\n",
      "100%|██████████| 204/204 [00:14<00:00, 13.61it/s]\n",
      "100%|██████████| 180/180 [00:12<00:00, 14.35it/s]\n",
      "100%|██████████| 232/232 [00:17<00:00, 13.44it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.07it/s]\n",
      "100%|██████████| 177/177 [00:14<00:00, 12.21it/s]\n",
      "100%|██████████| 37/37 [00:02<00:00, 15.45it/s]\n",
      "100%|██████████| 183/183 [00:14<00:00, 12.91it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19.97it/s]\n",
      "100%|██████████| 190/190 [00:14<00:00, 13.55it/s]\n",
      "100%|██████████| 29/29 [00:01<00:00, 15.94it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 14.97it/s]\n",
      "100%|██████████| 187/187 [00:13<00:00, 13.61it/s]\n",
      "100%|██████████| 129/129 [00:08<00:00, 14.46it/s]\n",
      "100%|██████████| 41/41 [00:02<00:00, 15.34it/s]\n",
      "100%|██████████| 37/37 [06:23<00:00, 10.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/votes_house_peltzman/Foreign/*')):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_house_peltzman_edges/Foreign/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and create thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold_intersx(df, weight):\t#df is the edgelist, weight is the weight of the edge\n",
    "\n",
    "\tdef _midpoint(p1, p2):\n",
    "\t\treturn {'x': (p1['x']+p2['x'])/2, 'y': (p1['y']+p2['y'])/2}\n",
    "\n",
    "\tdef line_intersection(in_party, out_party, intersect_points):\n",
    "\t\tindex_in = np.argmax(in_party[1])\n",
    "\t\tindex_out = np.argmax(out_party[1])\n",
    "\n",
    "        # points of the mean of the distributions \n",
    "\t\tpoint_in={'x': in_party[0][index_in], 'y': in_party[1][index_in]}\n",
    "\t\tpoint_out={'x': out_party[0][index_out], 'y': out_party[1][index_out]}\n",
    "\n",
    "        # medianpoint (mean of the means) of the two distributions\n",
    "\t\tmidpoint = _midpoint(point_in, point_out)\n",
    "        \n",
    "        #find index of intersection closer to midpoint\n",
    "\t\tindex_closer = np.argmin([np.sqrt( (p[0] - midpoint['x'])**2 + (p[1] - midpoint['y'])**2 ) for p in intersect_points])\n",
    "\n",
    "        # return x value of closer intersection\n",
    "\t\treturn intersect_points[index_closer][0]\n",
    "\n",
    "\tx0 = df.loc[(df['party']=='in')&(df['weight'] == weight)]['perc']\n",
    "\tx1 = df.loc[(df['party']=='out')&(df['weight'] == weight)]['perc']\n",
    "    \n",
    "\tbw = len(x0)**(-1./(2+4))\n",
    "\tkde0 = gaussian_kde(x0, bw_method=bw)\n",
    "\tbw = len(x1)**(-1./(2+4))\n",
    "\tkde1 = gaussian_kde(x1, bw_method=bw)\n",
    "\n",
    "\txmin = min(x0.min(), x1.min())\n",
    "\txmax = max(x0.max(), x1.max())\n",
    "\tdx = 0.2 * (xmax - xmin) # add a 20% margin, as the kde is wider than the data\n",
    "\txmin -= dx\n",
    "\txmax += dx\n",
    "\n",
    "\tx = np.linspace(xmin, xmax, 500)\n",
    "\tkde0_x = kde0(x)\n",
    "\tkde1_x = kde1(x)\n",
    "\tinters_x = np.minimum(kde0_x, kde1_x)\n",
    "\n",
    "\tidx = np.argwhere(np.diff(np.sign(kde0_x - kde1_x))).flatten()\n",
    "    \n",
    "\tthreshold = line_intersection([x, kde0_x], [x, kde0_x], [[x,y] for x,y in zip (x[idx], kde1_x[idx])])\n",
    "\tarea_inters_x = np.trapz(inters_x, x)\n",
    "\n",
    "\treturn threshold, area_inters_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:43<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob('../dataset/edgelists/votes_house_peltzman_edges/Internal/*')):\n",
    "\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\tdf_congress = pd.read_csv(csv)\n",
    "\n",
    "\tthreshold_pos, area_pos = compute_threshold_intersx(df_congress, 1)\n",
    "\tthreshold_neg, area_neg = compute_threshold_intersx(df_congress, -1)\n",
    "\tlen_df = len(df_congress)\n",
    "\n",
    "\t# Create a DataFrame with the desired columns and header\n",
    "\tdf_output = pd.DataFrame({\n",
    "\t\t'pos_threshold': [threshold_pos],\n",
    "\t\t'pos_area': [area_pos],\n",
    "\t\t'neg_threshold': [threshold_neg],\n",
    "\t\t'neg_area': [area_neg],\n",
    "\t\t'n_votes': [len_df]\n",
    "\t})\n",
    "\n",
    "\t# Save the DataFrame to CSV with the specified filename and header\n",
    "\toutput_filename = f'{n_congress}_dic_thresholds_norm.csv'\n",
    "\tdf_output.to_csv('../dataset/thresholds/house_peltzman_thresholds/Internal/' + output_filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in glob.glob('../dataset/edgelists/votes_house_peltzman_edges/Foreign/*'):\n",
    "\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\tdf_congress = pd.read_csv(csv)\n",
    "\n",
    "\tthreshold_pos, area_pos = compute_threshold_intersx(df_congress, 1)\n",
    "\tthreshold_neg, area_neg = compute_threshold_intersx(df_congress, -1)\n",
    "\tlen_df = len(df_congress)\n",
    "\n",
    "\t# Create a DataFrame with the desired columns and header\n",
    "\tdf_output = pd.DataFrame({\n",
    "\t\t'pos_threshold': [threshold_pos],\n",
    "\t\t'pos_area': [area_pos],\n",
    "\t\t'neg_threshold': [threshold_neg],\n",
    "\t\t'neg_area': [area_neg],\n",
    "\t\t'n_votes': [len_df]\n",
    "\t})\n",
    "\n",
    "\t# Save the DataFrame to CSV with the specified filename and header\n",
    "\toutput_filename = f'{n_congress}_dic_thresholds_norm.csv'\n",
    "\tdf_output.to_csv('../dataset/thresholds/house_peltzman_thresholds/Foreign/' + output_filename, header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USA_Congress_SigNetEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
