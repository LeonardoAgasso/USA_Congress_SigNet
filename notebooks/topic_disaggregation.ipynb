{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic disaggregation\n",
    "\n",
    "### Repeat the same process on data previously disaggregated according to the categories of the vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import glob, os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from shapely.geometry import LineString\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../local/bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_members_df(members, party_codes):\n",
    "    temp_congress = members.groupby('icpsr', as_index=False)[['congress']].agg(lambda x: list(x))                                                           # group by icpsr and aggregate the congress numbers into a list\n",
    "    temp_party = members.groupby('icpsr', as_index=False)[['party_code']].agg(lambda x: list(set(x)))                                                       # group by icpsr and aggregate the party codes into a list\n",
    "    temp_congress = temp_congress.merge(temp_party)                                                                                                         # merge the two dataframes\n",
    "    temp_congress['bioname'] = temp_congress['icpsr'].map(members[['icpsr', 'bioname']].set_index('icpsr').to_dict()['bioname'])                            # insert the bioname based on the icpsr \n",
    "    temp_congress['state_abbrev'] = temp_congress['icpsr'].map(members[['icpsr', 'state_abbrev']].set_index('icpsr').to_dict()['state_abbrev'])             # insert the state_abbrev based on the icpsr\n",
    "    party_codes_dic = party_codes[['party_name', 'party_code']].set_index('party_code').to_dict()['party_name']                                             # create a dictionary for the party codes\n",
    "    temp_congress['party_name'] = temp_congress['party_code'].apply(lambda x: [party_codes_dic[y] for y in x])                                              # insert the party name based on the party code\n",
    "    return temp_congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv('../dataset/HSall_members.csv')\n",
    "party_codes = pd.read_csv('../dataset/HSall_parties.csv')\n",
    "\n",
    "members_info = create_members_df(members, party_codes)\n",
    "\n",
    "member_party_dict = members_info.set_index('icpsr')['party_name'].to_dict()\t\t# member_id -> party_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edgelist_from_congress(congress, members_party_dict):\n",
    "\tedgelist = pd.DataFrame()\n",
    "\n",
    "\tfor voteid in tqdm(set(congress['id'])):                 # iterate over all votes id (ids are unique for each vote)\n",
    "\n",
    "\t\ttemp = congress[congress['id'] == voteid]            # select the rows where the vote id is equal to the current vote id            \n",
    "\n",
    "\t\tyy = temp[temp['vote']=='Yea']['icpsr']              # select the icpsr of the members that voted \"Yea\"\n",
    "\t\tnn = temp[temp['vote']=='Nay']['icpsr']                         \n",
    "\n",
    "\t\ty = itertools.combinations(yy, 2)                    # all possible combinations of 2 members that voted \"Yea\"\n",
    "\t\tn = itertools.combinations(nn, 2)                \n",
    "\t\to = itertools.product(yy, nn)                        # cartesian product of the 2 series\n",
    "\n",
    "\t\ty = pd.DataFrame(y, columns = ['source', 'target'])  # create a dataframe from the combinations of \"Yea\" voters\n",
    "\t\ty['weight'] = 1                                      # add a column with the weight of the edge\n",
    "\t\ty['count'] = 1                                         \n",
    "\n",
    "\t\tn = pd.DataFrame(n, columns = ['source', 'target'])     \n",
    "\t\tn['weight'] = 1                                         \n",
    "\t\tn['count'] = 1                                          \n",
    "\n",
    "\t\to = pd.DataFrame(o, columns = ['source', 'target'])     \n",
    "\t\to['weight'] = -1                                     # same but the link is negative                    \n",
    "\t\to['count'] = 1                                          \n",
    "\n",
    "\t\tedgelist = pd.concat([edgelist, y, n, o])\n",
    "\t\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count                  \n",
    "\n",
    "\tedgelist = pd.concat([edgelist, pd.DataFrame({\n",
    "\t\t'source': edgelist['target'],                        # new columns based on old columns: \n",
    "\t\t'target': edgelist['source'],                        #   'newcolumn': dataframe['oldcolumn']\n",
    "\t\t'weight': edgelist['weight'],\n",
    "\t\t'count': edgelist['count']})])\n",
    "\n",
    "\tedgelist = edgelist.loc[edgelist['source'] < edgelist['target']]                    # remove duplicates\n",
    "\tedgelist = edgelist.groupby(['source', 'target', 'weight']).sum().reset_index()     # group by source, target and weight and sum the count\n",
    "\tedgelist['party'] = edgelist.apply(lambda row: 'in' if members_party_dict[row['source']] == members_party_dict[row['target']] else 'out', axis=1)   # create a column with the party of the edge\n",
    "\n",
    "\tmap_votes = edgelist.groupby(['source', 'target'])['count'].sum().to_dict()                                                                         # create a dictionary with the number of votes togheter for each pair of nodes                               \n",
    "\n",
    "\tedgelist['votes_togheter'] = edgelist[['source', 'target']].apply(lambda x: map_votes[(x['source'], x['target'])], axis=1)\n",
    "\tedgelist['perc'] = edgelist['count']/edgelist['votes_togheter']\n",
    "\n",
    "\treturn edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_path = '../dataset/download_votes_merged/*'\n",
    "congress_path_senate = '../dataset/download_votes_merged_senate/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 32/41 [00:24<00:07,  1.16it/s]/tmp/ipykernel_1437/3165551236.py:7: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "100%|██████████| 41/41 [00:35<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a weighted bipartite graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Iterate through each CSV file\n",
    "for csv_file in tqdm(glob.glob(congress_path)):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Count the occurrences of each pair of Clausen and Peltzman categories\n",
    "    counts = df.groupby([\"Clausen\", \"Peltzman\"]).size().reset_index(name=\"count\")\n",
    "    \n",
    "    # Add edges to the graph with weights based on the counts\n",
    "    for _, row in counts.iterrows():\n",
    "        clausen_category = row[\"Clausen\"]\n",
    "        peltzman_category = row[\"Peltzman\"]\n",
    "        count = row[\"count\"]\n",
    "        \n",
    "        G.add_node(clausen_category, bipartite=0)\n",
    "        G.add_node(peltzman_category, bipartite=1)\n",
    "        G.add_edge(clausen_category, peltzman_category, weight=count)\n",
    "\n",
    "# Now you have a weighted bipartite graph (G) with edges representing the co-occurrences\n",
    "# between Clausen and Peltzman categories and weights representing the number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clausen categories:  ['Agriculture', 'Civil Liberties', 'Foreign and Defense Policy', 'Government Management', 'Miscellaneous Policy', 'Social Welfare']\n",
      "Number of Clausen categories:  6\n",
      "Peltzman categories:  ['Budget Special Interest', 'Regulation General Interest', 'Regulation Special Interest', 'Domestic Social Policy', 'Defense Policy Budget', 'Defense Policy Resolutions', 'Foreign Policy Budget', 'Foreign Policy Resolutions', 'Budget General Interest', 'D. C.', 'Government Organization', 'Indian Affairs', 'Internal Organization']\n",
      "Number of Peltzman categories:  13\n"
     ]
    }
   ],
   "source": [
    "print('Clausen categories: ', [n for n in G.nodes() if G.nodes[n]['bipartite'] == 0])\n",
    "print('Number of Clausen categories: ', len([n for n in G.nodes() if G.nodes[n]['bipartite'] == 0]))\n",
    "\n",
    "print('Peltzman categories: ', [n for n in G.nodes() if G.nodes[n]['bipartite'] == 1])\n",
    "print('Number of Peltzman categories: ', len([n for n in G.nodes() if G.nodes[n]['bipartite'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaggregate the congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clausen_cat_list = [n for n in G.nodes() if G.nodes[n]['bipartite'] == 0]\n",
    "peltzman_cat_list = [n for n in G.nodes() if G.nodes[n]['bipartite'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clausen_cat_dic = {x: re.sub(' ', '_', x) for x in clausen_cat_list}\n",
    "peltzman_cat_dic = {x: re.sub(' ', '_', x) for x in peltzman_cat_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../dataset/votes_house_clausen', exist_ok=True)\n",
    "os.makedirs('../dataset/votes_senate_clausen', exist_ok=True)\n",
    "\n",
    "os.makedirs('../dataset/votes_house_peltzman', exist_ok=True)\n",
    "os.makedirs('../dataset/votes_senate_peltzman', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clausen in clausen_cat_dic.values():\n",
    "\tos.makedirs('../dataset/votes_house_clausen/'+clausen, exist_ok=True)\n",
    "\tos.makedirs('../dataset/votes_senate_clausen/'+clausen, exist_ok=True)\n",
    "\n",
    "for peltzman in peltzman_cat_dic.values():\n",
    "\tos.makedirs('../dataset/votes_house_peltzman/'+peltzman, exist_ok=True)\n",
    "\tos.makedirs('../dataset/votes_senate_peltzman/'+peltzman, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 32/41 [02:00<00:34,  3.84s/it]/tmp/ipykernel_867/1185449784.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_congress = pd.read_csv(csv)\n",
      "100%|██████████| 41/41 [03:00<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob(congress_path)):\n",
    "    n_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\n",
    "    df_congress = pd.read_csv(csv)\n",
    "\n",
    "    for i in clausen_cat_dic.keys():\n",
    "        filtered_df = df_congress[df_congress['Clausen'] == i]\n",
    "        if not filtered_df.empty:\n",
    "            filtered_df.to_csv('../dataset/votes_house_clausen/'+clausen_cat_dic[i]+'/congress_'+str(n_congress)+'.csv', index=False)\n",
    "\n",
    "    for i in peltzman_cat_dic.keys():\n",
    "        filtered_df = df_congress[df_congress['Peltzman'] == i]\n",
    "        if not filtered_df.empty:\n",
    "            filtered_df.to_csv('../dataset/votes_house_peltzman/'+peltzman_cat_dic[i]+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:35<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(glob.glob(congress_path_senate)):\n",
    "    n_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\n",
    "    df_congress = pd.read_csv(csv)\n",
    "\n",
    "    for i in clausen_cat_dic.keys():\n",
    "        filtered_df = df_congress[df_congress['Clausen'] == i]\n",
    "        if not filtered_df.empty:\n",
    "            filtered_df.to_csv('../dataset/votes_senate_clausen/'+clausen_cat_dic[i]+'/congress_'+str(n_congress)+'.csv', index=False)\n",
    "\n",
    "    for i in peltzman_cat_dic.keys():\n",
    "        filtered_df = df_congress[df_congress['Peltzman'] == i]\n",
    "        if not filtered_df.empty:\n",
    "            filtered_df.to_csv('../dataset/votes_senate_peltzman/'+peltzman_cat_dic[i]+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create edgelists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../dataset/edgelists/', exist_ok=True)\n",
    "\n",
    "os.makedirs('../dataset/edgelists/votes_house_clausen_edges/', exist_ok=True)\n",
    "os.makedirs('../dataset/edgelists/votes_house_peltzman_edges/', exist_ok=True)\n",
    "\n",
    "os.makedirs('../dataset/edgelists/votes_senate_clausen_edges/', exist_ok=True)\n",
    "os.makedirs('../dataset/edgelists/votes_senate_peltzman_edges/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clausen in clausen_cat_dic.values():\n",
    "\tos.makedirs('../dataset/edgelists/votes_house_clausen_edges/'+clausen, exist_ok=True)\n",
    "\tos.makedirs('../dataset/edgelists/votes_senate_clausen_edges/'+clausen, exist_ok=True)\n",
    "\n",
    "for peltzman in peltzman_cat_dic.values():\n",
    "\tos.makedirs('../dataset/edgelists/votes_house_peltzman_edges/'+peltzman, exist_ok=True)\n",
    "\tos.makedirs('../dataset/edgelists/votes_senate_peltzman_edges/'+peltzman, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create house of representatives edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clausen in clausen_cat_dic.values():\n",
    "\tfor csv in glob.glob('../dataset/votes_house_clausen/'+clausen+'/*'):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_house_clausen_edges/'+clausen+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peltzman in peltzman_cat_dic.values():\n",
    "\tfor csv in glob.glob('../dataset/votes_house_peltzman/'+peltzman+'/*'):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_house_peltzman_edges/'+peltzman+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create senate edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clausen in clausen_cat_dic.values():\n",
    "\tfor csv in glob.glob('../dataset/votes_senate_clausen/'+clausen+'/*'):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_senate_clausen_edges/'+clausen+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peltzman in peltzman_cat_dic.values():\n",
    "\tfor csv in glob.glob('../dataset/votes_senate_peltzman/'+peltzman+'/*'):\n",
    "\t\tn_congress = int(os.path.basename(csv).replace('congress_', '').replace('.csv', ''))\n",
    "\t\tdf_congress = pd.read_csv(csv)\n",
    "\t\tedgelist = create_edgelist_from_congress(df_congress, member_party_dict)\n",
    "\t\tedgelist.to_csv('../dataset/edgelists/votes_senate_peltzman_edges/'+peltzman+'/congress_'+str(n_congress)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and create thresholds files for the edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir_name = '../dataset/thersholds/'\n",
    "\n",
    "os.makedirs(main_dir_name, exist_ok=True)\n",
    "\n",
    "os.makedirs(main_dir_name + 'house_clausen_thresholds/', exist_ok=True)\n",
    "os.makedirs(main_dir_name + 'house_peltzman_thresholds/', exist_ok=True)\n",
    "\n",
    "os.makedirs(main_dir_name + 'senate_clausen_thresholds/', exist_ok=True)\n",
    "os.makedirs(main_dir_name + 'senate_peltzman_thresholds/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clausen in clausen_cat_dic.values():\n",
    "\tos.makedirs(main_dir_name + 'house_clausen_thresholds/' + clausen, exist_ok=True)\n",
    "\tos.makedirs(main_dir_name + 'senate_clausen_thresholds/' + clausen, exist_ok=True)\n",
    "\n",
    "for peltzman in peltzman_cat_dic.values():\n",
    "\tos.makedirs(main_dir_name + 'house_peltzman_thresholds/' + peltzman, exist_ok=True)\n",
    "\tos.makedirs(main_dir_name + 'senate_peltzman_thresholds/' + peltzman, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the analysis on the disaggregated data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USA_Congress_SigNetEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
